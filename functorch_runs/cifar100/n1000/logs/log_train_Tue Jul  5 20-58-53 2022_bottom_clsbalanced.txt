2022-07-05 20:58:53,841: INFO: Hyperparameters
{'backbone': 'alexnet',
 'batch_size': 1000,
 'class_balanced': True,
 'config': 'src/configs/cifar100.yml',
 'criterion': 'NLLLoss',
 'criterion_kwargs': None,
 'dataset': 'cifar100',
 'dataset_dir': './data',
 'dont_train': False,
 'early_stopping_kwargs': {'min_delta': 0.001,
                           'min_epochs': 250,
                           'patience': 12},
 'epochs': 1000,
 'logdir': PosixPath('cifar100/n1000/logs'),
 'lr': 0.01,
 'num_classes': 100,
 'num_workers': 2,
 'optimizer': 'sgd',
 'optimizer_kwargs': {'momentum': 0.9, 'weight_decay': 0.01},
 'output_dir': PosixPath('cifar100/n1000'),
 'per_class': False,
 'random': False,
 'resume': None,
 'scheduler': 'reduceonplateau',
 'scheduler_kwargs': {'factor': 0.2,
                      'min_lr': 1e-07,
                      'patience': 10,
                      'threshold': 0.001},
 'seed': 0,
 'test_model': None,
 'topn': 1000,
 'transformation_kwargs': {'normalize': {'mean': [0.5071, 0.4867, 0.4408],
                                         'std': [0.2675, 0.2565, 0.2761]}},
 'use_saved_best_inds': None,
 'val_percent': 0.1,
 'wandb': False}
2022-07-05 20:58:56,056: INFO: Dataset
Dataset CIFAR100
    Number of datapoints: 50000
    Root location: ./data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])
           )
2022-07-05 20:58:57,410: INFO: Test Dataset
Dataset CIFAR100
    Number of datapoints: 10000
    Root location: ./data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])
           )
2022-07-05 20:58:57,767: INFO: all_similarities.shape: (100, 50000), all_imginds.shape: (100, 50000)
2022-07-05 20:59:10,819: INFO: Model Summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Sequential: 1-1                        [-1, 1024]                --
|    └─Conv2d: 2-1                       [-1, 64, 16, 16]          1,792
|    └─MaxPool2d: 2-2                    [-1, 64, 8, 8]            --
|    └─ReLU: 2-3                         [-1, 64, 8, 8]            --
|    └─Conv2d: 2-4                       [-1, 192, 8, 8]           110,784
|    └─MaxPool2d: 2-5                    [-1, 192, 4, 4]           --
|    └─ReLU: 2-6                         [-1, 192, 4, 4]           --
|    └─Conv2d: 2-7                       [-1, 384, 4, 4]           663,936
|    └─ReLU: 2-8                         [-1, 384, 4, 4]           --
|    └─Conv2d: 2-9                       [-1, 256, 4, 4]           884,992
|    └─ReLU: 2-10                        [-1, 256, 4, 4]           --
|    └─Conv2d: 2-11                      [-1, 256, 4, 4]           590,080
|    └─MaxPool2d: 2-12                   [-1, 256, 2, 2]           --
|    └─ReLU: 2-13                        [-1, 256, 2, 2]           --
|    └─Flatten: 2-14                     [-1, 1024]                --
├─Sequential: 1-2                        [-1, 100]                 --
|    └─Dropout: 2-15                     [-1, 1024]                --
|    └─Linear: 2-16                      [-1, 512]                 524,800
|    └─ReLU: 2-17                        [-1, 512]                 --
|    └─Dropout: 2-18                     [-1, 512]                 --
|    └─Linear: 2-19                      [-1, 256]                 131,328
|    └─ReLU: 2-20                        [-1, 256]                 --
|    └─Linear: 2-21                      [-1, 100]                 25,700
|    └─LogSoftmax: 2-22                  [-1, 100]                 --
==========================================================================================
Total params: 2,933,412
Trainable params: 2,933,412
Non-trainable params: 0
Total mult-adds (M): 45.34
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.33
Params size (MB): 11.19
Estimated Total Size (MB): 11.54
==========================================================================================
2022-07-05 20:59:18,225: INFO: Epoch[   1] Loss: 17.31	Accuracy: 1.556	Val_Loss: 6.030	Val_Acc: 3.000
2022-07-05 20:59:18,229: INFO: Epoch[   1] Test Accuracy: 0.840
2022-07-05 20:59:36,030: INFO: Epoch[  51] Loss: 4.60	Accuracy: 1.889	Val_Loss: 4.589	Val_Acc: 0.000
2022-07-05 20:59:36,035: INFO: Epoch[  51] Test Accuracy: 1.310
2022-07-05 20:59:53,574: INFO: Epoch[ 101] Loss: 4.45	Accuracy: 4.000	Val_Loss: 4.491	Val_Acc: 2.000
2022-07-05 20:59:53,576: INFO: Epoch[ 101] Test Accuracy: 3.120
2022-07-05 21:00:12,227: INFO: Epoch[ 151] Loss: 4.21	Accuracy: 6.111	Val_Loss: 4.350	Val_Acc: 5.000
2022-07-05 21:00:12,229: INFO: Epoch[ 151] Test Accuracy: 5.080
2022-07-05 21:00:31,203: INFO: Epoch[ 201] Loss: 3.98	Accuracy: 7.222	Val_Loss: 4.245	Val_Acc: 7.000
2022-07-05 21:00:31,205: INFO: Epoch[ 201] Test Accuracy: 5.570
2022-07-05 21:00:49,392: INFO: Epoch[ 251] Loss: 3.75	Accuracy: 11.222	Val_Loss: 4.212	Val_Acc: 9.000
2022-07-05 21:00:49,394: INFO: Epoch[ 251] Test Accuracy: 6.540
2022-07-05 21:00:50,311: INFO: Epoch: 254 Early stopping counter 1 of 12
2022-07-05 21:00:51,107: INFO: Epoch: 256 Early stopping counter 1 of 12
2022-07-05 21:00:51,441: INFO: Epoch: 257 Early stopping counter 2 of 12
2022-07-05 21:00:51,864: INFO: Epoch: 258 Early stopping counter 3 of 12
2022-07-05 21:00:53,136: INFO: Epoch: 262 Early stopping counter 1 of 12
2022-07-05 21:00:53,433: INFO: Epoch: 263 Early stopping counter 2 of 12
2022-07-05 21:00:53,737: INFO: Epoch: 264 Early stopping counter 3 of 12
2022-07-05 21:00:54,060: INFO: Epoch: 265 Early stopping counter 4 of 12
2022-07-05 21:00:54,377: INFO: Epoch: 266 Early stopping counter 5 of 12
2022-07-05 21:00:54,696: INFO: Epoch: 267 Early stopping counter 6 of 12
2022-07-05 21:00:55,006: INFO: Epoch: 268 Early stopping counter 7 of 12
2022-07-05 21:00:55,320: INFO: Epoch: 269 Early stopping counter 8 of 12
2022-07-05 21:00:55,626: INFO: Epoch: 270 Early stopping counter 9 of 12
2022-07-05 21:00:55,925: INFO: Epoch: 271 Early stopping counter 10 of 12
2022-07-05 21:00:56,225: INFO: Epoch: 272 Early stopping counter 11 of 12
2022-07-05 21:00:56,554: INFO: Epoch: 273 Early stopping counter 12 of 12
2022-07-05 21:00:56,555: INFO: Early stopping
2022-07-05 21:00:56,603: INFO: Trained for 273 Epochs.
2022-07-05 21:00:57,558: INFO: ('Accuracy on Train Set', 17.222222685813904)
2022-07-05 21:00:59,445: INFO: (637, 'correctly labeled out of', 10000)
2022-07-05 21:00:59,447: INFO: ('Accuracy on Test Set:', 6.370000000000001)
2022-07-05 21:00:59,619: INFO: Saved model at cifar100/n1000/Greedy_Model_1000n_Epochs_1000_Early_Stop_273_Test_Acc_6_clsbalanced.pth
2022-07-05 21:00:59,620: INFO: Training Complete
