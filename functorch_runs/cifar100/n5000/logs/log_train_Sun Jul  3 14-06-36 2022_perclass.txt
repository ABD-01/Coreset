2022-07-03 14:06:36,028: INFO: Hyperparameters
{'backbone': 'alexnet',
 'batch_size': 1000,
 'class_balanced': False,
 'config': 'src/configs/cifar100.yml',
 'criterion': 'NLLLoss',
 'criterion_kwargs': None,
 'dataset': 'cifar100',
 'dataset_dir': './data',
 'dont_train': False,
 'early_stopping_kwargs': {'min_delta': 0.001, 'patience': 12},
 'epochs': 1000,
 'logdir': PosixPath('cifar100/logs'),
 'lr': 0.01,
 'num_classes': 100,
 'num_workers': 2,
 'optimizer': 'sgd',
 'optimizer_kwargs': {'momentum': 0.9, 'weight_decay': 0.01},
 'output_dir': PosixPath('cifar100'),
 'per_class': True,
 'random': False,
 'resume': None,
 'scheduler': 'reduceonplateau',
 'scheduler_kwargs': {'factor': 0.2,
                      'min_lr': 1e-07,
                      'patience': 10,
                      'threshold': 0.001},
 'seed': 0,
 'test_model': None,
 'topn': 5000,
 'transformation_kwargs': {'normalize': {'mean': [0.5071, 0.4867, 0.4408],
                                         'std': [0.2675, 0.2565, 0.2761]}},
 'use_saved_best_inds': None,
 'val_percent': 0.1,
 'wandb': False}
2022-07-03 14:06:37,026: INFO: Dataset
Dataset CIFAR100
    Number of datapoints: 50000
    Root location: ./data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])
           )
2022-07-03 14:06:37,844: INFO: Test Dataset
Dataset CIFAR100
    Number of datapoints: 10000
    Root location: ./data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])
           )
2022-07-03 14:06:37,868: INFO: all_similarities_perclass.shape: (100, 100, 500), all_imginds_perclass.shape: (100, 100, 500)
2022-07-03 14:06:37,870: DEBUG: (array([0]), array([50000]))
2022-07-03 14:06:37,874: DEBUG: (array([1]), array([50000]))
2022-07-03 14:06:37,876: DEBUG: (array([2]), array([50000]))
2022-07-03 14:06:37,879: DEBUG: (array([3]), array([50000]))
2022-07-03 14:06:37,882: DEBUG: (array([4]), array([50000]))
2022-07-03 14:06:37,885: DEBUG: (array([5]), array([50000]))
2022-07-03 14:06:37,888: DEBUG: (array([6]), array([50000]))
2022-07-03 14:06:37,891: DEBUG: (array([7]), array([50000]))
2022-07-03 14:06:37,894: DEBUG: (array([8]), array([50000]))
2022-07-03 14:06:37,897: DEBUG: (array([9]), array([50000]))
2022-07-03 14:06:37,900: DEBUG: (array([10]), array([50000]))
2022-07-03 14:06:37,902: DEBUG: (array([11]), array([50000]))
2022-07-03 14:06:37,905: DEBUG: (array([12]), array([50000]))
2022-07-03 14:06:37,908: DEBUG: (array([13]), array([50000]))
2022-07-03 14:06:37,911: DEBUG: (array([14]), array([50000]))
2022-07-03 14:06:37,914: DEBUG: (array([15]), array([50000]))
2022-07-03 14:06:37,916: DEBUG: (array([16]), array([50000]))
2022-07-03 14:06:37,920: DEBUG: (array([17]), array([50000]))
2022-07-03 14:06:37,922: DEBUG: (array([18]), array([50000]))
2022-07-03 14:06:37,925: DEBUG: (array([19]), array([50000]))
2022-07-03 14:06:37,928: DEBUG: (array([20]), array([50000]))
2022-07-03 14:06:37,931: DEBUG: (array([21]), array([50000]))
2022-07-03 14:06:37,933: DEBUG: (array([22]), array([50000]))
2022-07-03 14:06:37,936: DEBUG: (array([23]), array([50000]))
2022-07-03 14:06:37,939: DEBUG: (array([24]), array([50000]))
2022-07-03 14:06:37,942: DEBUG: (array([25]), array([50000]))
2022-07-03 14:06:37,945: DEBUG: (array([26]), array([50000]))
2022-07-03 14:06:37,947: DEBUG: (array([27]), array([50000]))
2022-07-03 14:06:37,951: DEBUG: (array([28]), array([50000]))
2022-07-03 14:06:37,953: DEBUG: (array([29]), array([50000]))
2022-07-03 14:06:37,956: DEBUG: (array([30]), array([50000]))
2022-07-03 14:06:37,959: DEBUG: (array([31]), array([50000]))
2022-07-03 14:06:37,962: DEBUG: (array([32]), array([50000]))
2022-07-03 14:06:37,965: DEBUG: (array([33]), array([50000]))
2022-07-03 14:06:37,968: DEBUG: (array([34]), array([50000]))
2022-07-03 14:06:37,971: DEBUG: (array([35]), array([50000]))
2022-07-03 14:06:37,974: DEBUG: (array([36]), array([50000]))
2022-07-03 14:06:37,976: DEBUG: (array([37]), array([50000]))
2022-07-03 14:06:37,979: DEBUG: (array([38]), array([50000]))
2022-07-03 14:06:37,982: DEBUG: (array([39]), array([50000]))
2022-07-03 14:06:37,985: DEBUG: (array([40]), array([50000]))
2022-07-03 14:06:37,988: DEBUG: (array([41]), array([50000]))
2022-07-03 14:06:37,991: DEBUG: (array([42]), array([50000]))
2022-07-03 14:06:37,994: DEBUG: (array([43]), array([50000]))
2022-07-03 14:06:37,997: DEBUG: (array([44]), array([50000]))
2022-07-03 14:06:38,000: DEBUG: (array([45]), array([50000]))
2022-07-03 14:06:38,003: DEBUG: (array([46]), array([50000]))
2022-07-03 14:06:38,006: DEBUG: (array([47]), array([50000]))
2022-07-03 14:06:38,009: DEBUG: (array([48]), array([50000]))
2022-07-03 14:06:38,012: DEBUG: (array([49]), array([50000]))
2022-07-03 14:06:38,015: DEBUG: (array([50]), array([50000]))
2022-07-03 14:06:38,017: DEBUG: (array([51]), array([50000]))
2022-07-03 14:06:38,020: DEBUG: (array([52]), array([50000]))
2022-07-03 14:06:38,023: DEBUG: (array([53]), array([50000]))
2022-07-03 14:06:38,026: DEBUG: (array([54]), array([50000]))
2022-07-03 14:06:38,029: DEBUG: (array([55]), array([50000]))
2022-07-03 14:06:38,032: DEBUG: (array([56]), array([50000]))
2022-07-03 14:06:38,035: DEBUG: (array([57]), array([50000]))
2022-07-03 14:06:38,038: DEBUG: (array([58]), array([50000]))
2022-07-03 14:06:38,041: DEBUG: (array([59]), array([50000]))
2022-07-03 14:06:38,044: DEBUG: (array([60]), array([50000]))
2022-07-03 14:06:38,047: DEBUG: (array([61]), array([50000]))
2022-07-03 14:06:38,050: DEBUG: (array([62]), array([50000]))
2022-07-03 14:06:38,052: DEBUG: (array([63]), array([50000]))
2022-07-03 14:06:38,055: DEBUG: (array([64]), array([50000]))
2022-07-03 14:06:38,058: DEBUG: (array([65]), array([50000]))
2022-07-03 14:06:38,061: DEBUG: (array([66]), array([50000]))
2022-07-03 14:06:38,063: DEBUG: (array([67]), array([50000]))
2022-07-03 14:06:38,066: DEBUG: (array([68]), array([50000]))
2022-07-03 14:06:38,069: DEBUG: (array([69]), array([50000]))
2022-07-03 14:06:38,072: DEBUG: (array([70]), array([50000]))
2022-07-03 14:06:38,075: DEBUG: (array([71]), array([50000]))
2022-07-03 14:06:38,078: DEBUG: (array([72]), array([50000]))
2022-07-03 14:06:38,081: DEBUG: (array([73]), array([50000]))
2022-07-03 14:06:38,084: DEBUG: (array([74]), array([50000]))
2022-07-03 14:06:38,086: DEBUG: (array([75]), array([50000]))
2022-07-03 14:06:38,089: DEBUG: (array([76]), array([50000]))
2022-07-03 14:06:38,092: DEBUG: (array([77]), array([50000]))
2022-07-03 14:06:38,096: DEBUG: (array([78]), array([50000]))
2022-07-03 14:06:38,100: DEBUG: (array([79]), array([50000]))
2022-07-03 14:06:38,104: DEBUG: (array([80]), array([50000]))
2022-07-03 14:06:38,108: DEBUG: (array([81]), array([50000]))
2022-07-03 14:06:38,111: DEBUG: (array([82]), array([50000]))
2022-07-03 14:06:38,114: DEBUG: (array([83]), array([50000]))
2022-07-03 14:06:38,117: DEBUG: (array([84]), array([50000]))
2022-07-03 14:06:38,120: DEBUG: (array([85]), array([50000]))
2022-07-03 14:06:38,123: DEBUG: (array([86]), array([50000]))
2022-07-03 14:06:38,125: DEBUG: (array([87]), array([50000]))
2022-07-03 14:06:38,128: DEBUG: (array([88]), array([50000]))
2022-07-03 14:06:38,131: DEBUG: (array([89]), array([50000]))
2022-07-03 14:06:38,134: DEBUG: (array([90]), array([50000]))
2022-07-03 14:06:38,137: DEBUG: (array([91]), array([50000]))
2022-07-03 14:06:38,140: DEBUG: (array([92]), array([50000]))
2022-07-03 14:06:38,142: DEBUG: (array([93]), array([50000]))
2022-07-03 14:06:38,145: DEBUG: (array([94]), array([50000]))
2022-07-03 14:06:38,148: DEBUG: (array([95]), array([50000]))
2022-07-03 14:06:38,151: DEBUG: (array([96]), array([50000]))
2022-07-03 14:06:38,154: DEBUG: (array([97]), array([50000]))
2022-07-03 14:06:38,156: DEBUG: (array([98]), array([50000]))
2022-07-03 14:06:38,159: DEBUG: (array([99]), array([50000]))
2022-07-03 14:06:38,161: DEBUG: best inds shape (5000,)
2022-07-03 14:06:43,583: INFO: Model Summary
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Sequential: 1-1                        [-1, 1024]                --
|    └─Conv2d: 2-1                       [-1, 64, 16, 16]          1,792
|    └─MaxPool2d: 2-2                    [-1, 64, 8, 8]            --
|    └─ReLU: 2-3                         [-1, 64, 8, 8]            --
|    └─Conv2d: 2-4                       [-1, 192, 8, 8]           110,784
|    └─MaxPool2d: 2-5                    [-1, 192, 4, 4]           --
|    └─ReLU: 2-6                         [-1, 192, 4, 4]           --
|    └─Conv2d: 2-7                       [-1, 384, 4, 4]           663,936
|    └─ReLU: 2-8                         [-1, 384, 4, 4]           --
|    └─Conv2d: 2-9                       [-1, 256, 4, 4]           884,992
|    └─ReLU: 2-10                        [-1, 256, 4, 4]           --
|    └─Conv2d: 2-11                      [-1, 256, 4, 4]           590,080
|    └─MaxPool2d: 2-12                   [-1, 256, 2, 2]           --
|    └─ReLU: 2-13                        [-1, 256, 2, 2]           --
|    └─Flatten: 2-14                     [-1, 1024]                --
├─Sequential: 1-2                        [-1, 100]                 --
|    └─Dropout: 2-15                     [-1, 1024]                --
|    └─Linear: 2-16                      [-1, 512]                 524,800
|    └─ReLU: 2-17                        [-1, 512]                 --
|    └─Dropout: 2-18                     [-1, 512]                 --
|    └─Linear: 2-19                      [-1, 256]                 131,328
|    └─ReLU: 2-20                        [-1, 256]                 --
|    └─Linear: 2-21                      [-1, 100]                 25,700
|    └─LogSoftmax: 2-22                  [-1, 100]                 --
==========================================================================================
Total params: 2,933,412
Trainable params: 2,933,412
Non-trainable params: 0
Total mult-adds (M): 45.34
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.33
Params size (MB): 11.19
Estimated Total Size (MB): 11.54
==========================================================================================
2022-07-03 14:06:51,320: INFO: Epoch[   1] Loss: 15.91	Accuracy: 0.933	Val_Loss: 5.886	Val_Acc: 0.400
2022-07-03 14:06:51,321: INFO: Epoch[   1] Test Accuracy: 0.750
2022-07-03 14:07:54,388: INFO: Epoch[  51] Loss: 4.53	Accuracy: 2.844	Val_Loss: 4.452	Val_Acc: 4.400
2022-07-03 14:07:54,388: INFO: Epoch[  51] Test Accuracy: 3.460
2022-07-03 14:08:57,419: INFO: Epoch[ 101] Loss: 4.09	Accuracy: 7.000	Val_Loss: 3.984	Val_Acc: 9.000
2022-07-03 14:08:57,419: INFO: Epoch[ 101] Test Accuracy: 5.480
2022-07-03 14:10:00,737: INFO: Epoch[ 151] Loss: 3.67	Accuracy: 11.556	Val_Loss: 3.559	Val_Acc: 15.400
2022-07-03 14:10:00,738: INFO: Epoch[ 151] Test Accuracy: 7.680
2022-07-03 14:10:13,056: INFO: Early stopping counter 1 of 12
2022-07-03 14:10:18,008: INFO: Early stopping counter 1 of 12
2022-07-03 14:10:41,777: INFO: Early stopping counter 1 of 12
2022-07-03 14:10:46,664: INFO: Early stopping counter 1 of 12
2022-07-03 14:10:51,526: INFO: Early stopping counter 1 of 12
2022-07-03 14:10:55,159: INFO: Early stopping counter 1 of 12
2022-07-03 14:10:56,374: INFO: Early stopping counter 2 of 12
2022-07-03 14:10:58,833: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:01,280: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:04,320: INFO: Epoch[ 201] Loss: 3.40	Accuracy: 14.067	Val_Loss: 3.300	Val_Acc: 19.600
2022-07-03 14:11:04,320: INFO: Epoch[ 201] Test Accuracy: 9.140
2022-07-03 14:11:06,782: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:08,008: INFO: Early stopping counter 2 of 12
2022-07-03 14:11:11,678: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:12,879: INFO: Early stopping counter 2 of 12
2022-07-03 14:11:15,335: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:16,564: INFO: Early stopping counter 2 of 12
2022-07-03 14:11:17,785: INFO: Early stopping counter 3 of 12
2022-07-03 14:11:21,442: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:25,121: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:26,356: INFO: Early stopping counter 2 of 12
2022-07-03 14:11:30,009: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:31,210: INFO: Early stopping counter 2 of 12
2022-07-03 14:11:33,676: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:34,909: INFO: Early stopping counter 2 of 12
2022-07-03 14:11:39,846: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:43,534: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:47,183: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:49,630: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:50,849: INFO: Early stopping counter 2 of 12
2022-07-03 14:11:55,761: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:58,204: INFO: Early stopping counter 1 of 12
2022-07-03 14:11:59,437: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:00,677: INFO: Early stopping counter 3 of 12
2022-07-03 14:12:03,137: INFO: Early stopping counter 1 of 12
2022-07-03 14:12:04,400: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:05,644: INFO: Early stopping counter 3 of 12
2022-07-03 14:12:07,473: INFO: Epoch[ 251] Loss: 3.23	Accuracy: 17.689	Val_Loss: 3.187	Val_Acc: 21.400
2022-07-03 14:12:07,473: INFO: Epoch[ 251] Test Accuracy: 9.760
2022-07-03 14:12:08,741: INFO: Early stopping counter 4 of 12
2022-07-03 14:12:09,971: INFO: Early stopping counter 5 of 12
2022-07-03 14:12:12,428: INFO: Early stopping counter 1 of 12
2022-07-03 14:12:13,672: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:14,911: INFO: Early stopping counter 3 of 12
2022-07-03 14:12:17,364: INFO: Early stopping counter 1 of 12
2022-07-03 14:12:18,583: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:21,054: INFO: Early stopping counter 1 of 12
2022-07-03 14:12:22,290: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:23,525: INFO: Early stopping counter 3 of 12
2022-07-03 14:12:24,767: INFO: Early stopping counter 4 of 12
2022-07-03 14:12:26,004: INFO: Early stopping counter 5 of 12
2022-07-03 14:12:27,241: INFO: Early stopping counter 6 of 12
2022-07-03 14:12:30,908: INFO: Early stopping counter 1 of 12
2022-07-03 14:12:32,148: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:34,642: INFO: Early stopping counter 1 of 12
2022-07-03 14:12:35,860: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:37,083: INFO: Early stopping counter 3 of 12
2022-07-03 14:12:39,546: INFO: Early stopping counter 1 of 12
2022-07-03 14:12:40,765: INFO: Early stopping counter 2 of 12
2022-07-03 14:12:41,986: INFO: Early stopping counter 3 of 12
2022-07-03 14:12:43,224: INFO: Early stopping counter 4 of 12
2022-07-03 14:12:44,478: INFO: Early stopping counter 5 of 12
2022-07-03 14:12:45,704: INFO: Early stopping counter 6 of 12
2022-07-03 14:12:46,936: INFO: Early stopping counter 7 of 12
2022-07-03 14:12:48,157: INFO: Early stopping counter 8 of 12
2022-07-03 14:12:49,394: INFO: Early stopping counter 9 of 12
2022-07-03 14:12:50,634: INFO: Early stopping counter 10 of 12
2022-07-03 14:12:51,882: INFO: Early stopping counter 11 of 12
2022-07-03 14:12:53,111: INFO: Early stopping counter 12 of 12
2022-07-03 14:12:53,112: INFO: Early stopping
2022-07-03 14:12:53,160: INFO: Trained for 288 Epochs.
2022-07-03 14:12:54,542: INFO: ('Accuracy on Train Set', 24.977777898311615)
2022-07-03 14:12:56,419: INFO: (1102, 'correctly labeled out of', 10000)
2022-07-03 14:12:56,419: INFO: ('Accuracy on Test Set:', 11.020000000000001)
2022-07-03 14:12:56,446: INFO: Saved model at cifar100/Greedy_Model_5000n_Epochs_1000_Early_Stop_288_Test_Acc_11__perclass.pth
2022-07-03 14:12:56,447: INFO: Training Complete
